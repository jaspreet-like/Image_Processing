{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Jaspreet_Task_4_Bonus.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzrGBSnagm-5"
      },
      "source": [
        "# Copyright 2020 IITK EE604A Image Processing. All Rights Reserved.\n",
        "# \n",
        "# Licensed under the MIT License. Use and/or modification of this code outside of EE604 must reference:\n",
        "#\n",
        "# Â© IITK EE604A Image Processing \n",
        "# https://github.com/ee604/ee604_assignments\n",
        "#\n",
        "# Author: Shashi Kant Gupta, Chiranjeev Prachand and Prof K. S. Venkatesh, Department of Electrical Engineering, IIT Kanpur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHTvLjIVgm_K"
      },
      "source": [
        "# Task 4 (Bonus Question): Template Matching and Visual Search\n",
        "\n",
        "In this bonus task, you will study about template matching algorithm, which is used to search and find a template image in a larger image. You will then use this method and techniques you learned in task1, task2, and task3 to search for a given \"target\" image in a large cluttered \"search\" image. This task of finding a target image is usually called a visual search task.\n",
        "\n",
        "In this assignment, you will be using this method in a preliminary setting. But this method can be easily generalized to complex visual search tasks. Instead of directly using the image pixels, you first extract features of those images using some deep learning methods or other computer vision algorithms and then apply the template matching method on extracted features instead of the image pixels.\n",
        "\n",
        "**Theories:** \n",
        "* Template Matching: [http://www.cse.psu.edu/~rtc12/CSE486/lecture07.pdf](http://www.cse.psu.edu/~rtc12/CSE486/lecture07.pdf)\n",
        "* Tempalte Matching (Optional): [https://docs.adaptive-vision.com/4.7/studio/machine_vision_guide/TemplateMatching.html](https://docs.adaptive-vision.com/4.7/studio/machine_vision_guide/TemplateMatching.html)\n",
        "* Template Matching Wikipedia: [https://en.wikipedia.org/wiki/Template_matching](https://en.wikipedia.org/wiki/Template_matching)\n",
        "* Visual Search (Optional): [http://www.scholarpedia.org/article/Visual_search](http://www.scholarpedia.org/article/Visual_search)\n",
        "\n",
        "---\n",
        "\n",
        "### Your Task\n",
        "You will be given a set of visual search tasks containing 156 various target images to search in 156 corresponding search images. All image contains only English alphabets. You have to write a python function that will return the (x, y) position of the target in the given search image. You have to use the template matching approach to find the location of the target image. But there's a problem, somehow the provided dataset got corrupted, and it contains lots of noises in it. Smartly using some image enhancement methods to make the images clearer and then applying template matching algorithms could help. It's up to you how you use the techniques taught in EE604 lectures to get the best score. Your score will be evaluated as `score = num_correct_prediction/156`\n",
        "\n",
        "* Assume the target image is of the same size in the search image.\n",
        "* Assume the target image is in the same orientation in the search image.\n",
        "* You are free to use any OpenCV module except `cv2.matchTemplate()`.\n",
        "\n",
        "**Example of Visual Search Task:**\n",
        "![](https://github.com/ee604/ee604_assignments/raw/master/assignment_2/imgs/Example.png)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfNBgnB0gm_Q",
        "outputId": "bed0b00b-ce34-4926-a2f9-1967b46275fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "pip install git+https://github.com/ee604/ee604_plugins"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ee604/ee604_plugins\n",
            "  Cloning https://github.com/ee604/ee604_plugins to /tmp/pip-req-build-0luwgrmk\n",
            "Requirement already satisfied (use --upgrade to upgrade): ee604-plugins==0.2.2 from git+https://github.com/ee604/ee604_plugins in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: ee604-plugins\n",
            "  Building wheel for ee604-plugins (setup.py): started\n",
            "  Building wheel for ee604-plugins (setup.py): finished with status 'done'\n",
            "  Created wheel for ee604-plugins: filename=ee604_plugins-0.2.2-cp36-none-any.whl size=2313 sha256=09477071dc13a0f48931ca754b827559384cf30a46deef443b830dfada0fef8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jxus4rju/wheels/34/a8/1d/ae3b7d209ecde89b4800a47ec55a61e7503bb9548bbb975806\n",
            "Successfully built ee604-plugins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/ee604/ee604_plugins /tmp/pip-req-build-0luwgrmk\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKmO5N7ugm_g",
        "outputId": "6d97f3f0-b171-4e20-fcd8-8bb1435ec386",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Importing required libraries\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ee604_plugins import download_dataset\n",
        "\n",
        "download_dataset(assignment_no=2, task_no=4)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFBp9ffBgm_n"
      },
      "source": [
        "X_img = np.load(\"data/search_img.npy\")\n",
        "Y_img = np.load(\"data/target_img.npy\")\n",
        "M_img = np.load(\"data/mask_img.npy\")\n",
        "\n",
        "sample_target = np.copy(Y_img[0])\n",
        "sample_search = np.copy(X_img[0])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ-gkRyrgm_t"
      },
      "source": [
        "# Do not change codes inside this cell\n",
        "\n",
        "def calc_search_score():\n",
        "    c = 0 \n",
        "    for k in range(len(X_img)):\n",
        "        x, y = searchTarget(np.copy(X_img[k]), np.copy(Y_img[k]))\n",
        "        c += M_img[k][x, y]\n",
        "        #print(c)\n",
        "    return round(c/len(X_img), 2)\n",
        "\n",
        "\n",
        "def Normalised_Cross_Correlation(window, target):\n",
        "    window = window - np.mean(window)\n",
        "    target = target - np.mean(target)\n",
        "    \n",
        "    corr = np.sum(window * target)\n",
        "    norm_factor = np.sqrt(np.sum(pow(window,2))) * np.sqrt(np.sum(pow(target,2)))\n",
        "\n",
        "    return corr/norm_factor\n",
        "\n",
        "\n",
        "def template_matching(img, target):\n",
        "    m, n = img.shape\n",
        "    tm, tn = target.shape\n",
        "    \n",
        "    (max_corr_i, max_corr_j) = (0, 0)\n",
        "    Maximum = 0\n",
        "    corr_matrix = np.zeros((m-tm, n-tn))\n",
        "\n",
        "    for i in range(0,m-tm):\n",
        "      for j in range(0,n-tn):\n",
        "        window = img[i:i+tm, j:j+tn]\n",
        "        corr_matrix[i][j] = Normalised_Cross_Correlation(window,target)\n",
        "\n",
        "        if(corr_matrix[i][j]>Maximum):\n",
        "          Maximum = corr_matrix[i][j]\n",
        "          (max_corr_i,max_corr_j) = (i,j)\n",
        "\n",
        "    return (max_corr_j, max_corr_i)\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvexU2h5gm_2"
      },
      "source": [
        "def searchTarget(search_img, target_img):\n",
        "    '''    \n",
        "    Inputs:                      \n",
        "    + search_img - image in which you have to search for the target, size = (512, 512) ==> (dim1, dim2)\n",
        "    + target_img - target image, size = (55, 55)\n",
        "    \n",
        "    Ouputs:\n",
        "    + x - index along the first dimension ('dim1') of the search image where the target is present\n",
        "    + y - index along the second dimension ('dim2') of the search image where the target is present\n",
        "    \n",
        "    Allowed external package:\n",
        "    + You are free to use any OpenCV/numpy module except 'cv2.matchTemplate()'.\n",
        "    \n",
        "    Hint:\n",
        "    + Make sure you properly map the index with respect to input image size i.e. (512, 512). \n",
        "      Generally convolution/ correlation operation will reduce your output size by the size \n",
        "      of templated image.\n",
        "    + Correlation operation can be written in terms of convolution operator.\n",
        "    + Use OpenCV's cv2.matchTemplate() to know which method works best and implement corresponding\n",
        "      method using other openCV modules.\n",
        "    + This algorithm can be implemented using the functions you wrote/ used for other three tasks.\n",
        "    \n",
        "    '''\n",
        "    x, y = 0, 0\n",
        "    \n",
        "    #############################\n",
        "    # Start your code from here #\n",
        "    #############################\n",
        "    \n",
        "    less_noisy_search_img = cv2.GaussianBlur(search_img, (7,7), 1)\n",
        "    less_noisy_target_img = cv2.GaussianBlur(target_img, (5,5), 1)\n",
        "    '''\n",
        "    v = cv2.matchTemplate(less_noisy_search_img,less_noisy_target_img,method = cv2.TM_CCOEFF_NORMED)\n",
        "    a,b,c,d = cv2.minMaxLoc(v)\n",
        "    y,x = d\n",
        "    '''\n",
        "    y,x = template_matching(less_noisy_search_img, less_noisy_target_img)\n",
        "    \n",
        "    #############################\n",
        "    # End your code here ########\n",
        "    ############################# \n",
        "    \n",
        "    return x, y"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPL-iEwygm_7",
        "outputId": "13c8a2de-cfb4-4a72-9516-fc14454648eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not change codes inside this cell\n",
        "score = calc_search_score()\n",
        "print(\"Your score:\", score)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "6.0\n",
            "7.0\n",
            "8.0\n",
            "9.0\n",
            "10.0\n",
            "11.0\n",
            "12.0\n",
            "12.0\n",
            "13.0\n",
            "13.0\n",
            "14.0\n",
            "15.0\n",
            "16.0\n",
            "16.0\n",
            "17.0\n",
            "18.0\n",
            "19.0\n",
            "19.0\n",
            "20.0\n",
            "21.0\n",
            "22.0\n",
            "23.0\n",
            "24.0\n",
            "25.0\n",
            "26.0\n",
            "27.0\n",
            "28.0\n",
            "29.0\n",
            "30.0\n",
            "31.0\n",
            "32.0\n",
            "33.0\n",
            "34.0\n",
            "35.0\n",
            "36.0\n",
            "37.0\n",
            "38.0\n",
            "39.0\n",
            "40.0\n",
            "41.0\n",
            "42.0\n",
            "43.0\n",
            "44.0\n",
            "44.0\n",
            "45.0\n",
            "46.0\n",
            "46.0\n",
            "47.0\n",
            "48.0\n",
            "49.0\n",
            "50.0\n",
            "51.0\n",
            "52.0\n",
            "53.0\n",
            "54.0\n",
            "55.0\n",
            "56.0\n",
            "57.0\n",
            "57.0\n",
            "58.0\n",
            "59.0\n",
            "60.0\n",
            "61.0\n",
            "62.0\n",
            "63.0\n",
            "64.0\n",
            "65.0\n",
            "66.0\n",
            "67.0\n",
            "68.0\n",
            "69.0\n",
            "70.0\n",
            "71.0\n",
            "72.0\n",
            "73.0\n",
            "74.0\n",
            "74.0\n",
            "75.0\n",
            "76.0\n",
            "77.0\n",
            "78.0\n",
            "79.0\n",
            "80.0\n",
            "80.0\n",
            "81.0\n",
            "82.0\n",
            "83.0\n",
            "84.0\n",
            "85.0\n",
            "86.0\n",
            "87.0\n",
            "88.0\n",
            "89.0\n",
            "90.0\n",
            "91.0\n",
            "92.0\n",
            "93.0\n",
            "94.0\n",
            "95.0\n",
            "96.0\n",
            "97.0\n",
            "98.0\n",
            "99.0\n",
            "100.0\n",
            "101.0\n",
            "102.0\n",
            "103.0\n",
            "104.0\n",
            "105.0\n",
            "106.0\n",
            "107.0\n",
            "108.0\n",
            "109.0\n",
            "110.0\n",
            "111.0\n",
            "112.0\n",
            "113.0\n",
            "114.0\n",
            "115.0\n",
            "116.0\n",
            "117.0\n",
            "118.0\n",
            "119.0\n",
            "120.0\n",
            "121.0\n",
            "122.0\n",
            "123.0\n",
            "124.0\n",
            "125.0\n",
            "126.0\n",
            "127.0\n",
            "128.0\n",
            "129.0\n",
            "130.0\n",
            "131.0\n",
            "132.0\n",
            "133.0\n",
            "133.0\n",
            "134.0\n",
            "135.0\n",
            "136.0\n",
            "137.0\n",
            "138.0\n",
            "139.0\n",
            "140.0\n",
            "141.0\n",
            "142.0\n",
            "143.0\n",
            "144.0\n",
            "145.0\n",
            "146.0\n",
            "Your score: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_D0JCMbgnAH"
      },
      "source": [
        "#It takes upto about 30 mins to run. It gives the ans as 0.94. It matches 146/156 pairs of (source, target) image."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}